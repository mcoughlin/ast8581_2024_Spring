{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from notebook.services.config import ConfigManager\n",
    "cm = ConfigManager()\n",
    "cm.update('livereveal', {\n",
    "        'width': 1920,\n",
    "        'height': 1080,\n",
    "        'scroll': True,\n",
    "})\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from IPython.lib.display import YouTubeVideo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 06 (Monday), AST 8581 / PHYS 8581 / CSCI 8581 / STAT 8581: Big Data in Astrophysics\n",
    "\n",
    "### Michael Coughlin <cough052@umn.edu>, Jie Ding <dingj@umn.edu>\n",
    "\n",
    "\n",
    "with contributions totally ripped off from Gautham Narayan (UIUC), Michael Steinbach (UMN), and Nico Adams (UMN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Where are we headed?\n",
    "\n",
    "Foundations of Data and Probability -> Statistical frameworks (Frequentist vs Bayesian) -> Estimating underlying distributions -> Analysis of Time series (periodicity) -> Analysis of Time series (variability) -> Analysis of Time series (stochastic processes) -> <b> Gaussian Processes </b> -> Decision Trees / Regression -> Dimensionality Reduction -> Principle Component Analysis -> Clustering -> Density Estimation / Anomaly Detection -> Supervised Learning -> Deep Learning -> Introduction to Databases - SQL -> Introduction to Databases - NoSQL -> Introduction to Multiprocessing -> Introduction to GPUs -> Unit Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Last Class: Stochastic Processes, Correlation Functions, and Gaussian Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Today: More Gaussian Processes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gaussian Process Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Gaussian Processes in Data Analysis\n",
    "\n",
    "A draw from $P[y(x^*)]$ would represent a prior prediction for the function value $y(x^*)$\n",
    "\n",
    "Typically we are more interested in the posterior prediction, drawn from $P[y(x^*)\\vert y^{\\rm obs}(x_{\\rm obs})]$\n",
    "\n",
    "$$ \\log L = - \\log | \\Sigma| - |y -u|^T \\Sigma^{-1} |y-u|$$\n",
    "\n",
    "\n",
    "$$ \\Sigma = (n x n)\\text{ matrix}$$ \n",
    "\n",
    "with \n",
    "\n",
    "$$ \\Sigma_{i,j} = \\text{Cov}(y(t_i), y(t_j)) = \\int_{-\\infty}^{\\infty} \\text{PSD} e^{2\\pi if |t_i - t_j|} \\,df $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The posterior PDF for $y(x^*)$ is a Gaussian, whose mean and standard deviation can be computed algebraically, and which is constrained by _all the previously observed $y(x)$_.\n",
    "\n",
    "\n",
    "<img src=\"figures/mfm_gp_example.png\" width=400> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GP Regression\n",
    "\n",
    "GP's provide a natural way to achieve high flexibility (and uncertainty) when _interpolating_ data. \n",
    "\n",
    "With the appropriate assumptions (e.g. Gaussian measurement errors), the calculation of the posterior for $y(x)$ is an _algebraic_ operation (no Monte Carlo required).\n",
    "\n",
    "Marginalization over the GP hyperparameters (the width of the kernel, for example) is more computationally expensive (involving the determinants of the matrices), but [fast methods have been developed](http://dan.iel.fm/george/current/user/hyper/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "During the first half of the semester, you got famililar with observations drawn from a distribution e.g. $y1$, drawn from a Gaussian distribution with mean $\\mu$ and variance $\\sigma^2$:\n",
    "\n",
    "\\begin{align}\n",
    "p(y_1 | \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left[ - \\frac{(y_1-\\mu)^2}{2 \\sigma^2} \\right] \n",
    "\\end{align}\n",
    "\n",
    "i.e.\n",
    "\n",
    "### $$y_1 \\sim \\mathcal{N}(\\mu,\\sigma^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If pair of variables $y_1$ and $y_2$, drawn from a *bivariate Gaussian distribution*. The *joint probability density* for $y_1$ and $y_2$ is:\n",
    "\n",
    "$$\\left[ \\begin{array}{l} y_1 \\\\ y_2 \\end{array} \\right] \\sim \\mathcal{N} \\left(\n",
    "\\left[ \\begin{array}{l} \\mu_1 \\\\ \\mu_2 \\end{array}  \\right] , \n",
    "\\left[ \\begin{array}{ll} \n",
    "\\sigma_1^2 & C \\\\\n",
    "C & \\sigma_2^2 \n",
    "\\end{array}  \\right] \n",
    "\\right),$$\n",
    "\n",
    "where \n",
    "\n",
    "### $$C = {\\rm cov}(y_1,y_2)$$ \n",
    "\n",
    "is the *covariance* between $y_1$ and $y_2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the first half of the semester, we dealt with independent variables i.e.\n",
    "\n",
    "### $$P(y_1 \\cap y_2) = P(y_1) \\cdot P(y_2) $$\n",
    "\n",
    "and consequently\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "P(y_2|y_1) = \\frac{P(y_1 \\cap y_2)}{P(y_1)} = P(y_2)\n",
    "\\end{align}\n",
    "\n",
    "If two variables are independent, then $C = 0$ (remember converse isn't true). \n",
    "\n",
    "The observations are *uncorrelated* so measuring $y_1$ doesn't teach us anything about $y_2$.\n",
    "\n",
    "(If in addition $\\mu_1 = \\mu_2$ and $\\sigma_1 = \\sigma_2$ the variables are i.i.d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### With time-series, $C \\ne 0$ \n",
    "\n",
    "If we know the value of $y_1$, the probability density for $y_2$ collapses to the the *conditional distribution* of $y_2$ given $y_1$:\n",
    "\n",
    "$$\n",
    "p(y_2 \\mid y_1) = \\mathcal{N} \\left( \\mu_2 + C (y_1-\\mu_1)/\\sigma_1^2, \\sigma_2^2-C^2\\sigma_1^2 \\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Now consider $N$ variables drawn from a multivariate Gaussian distribution:\n",
    "\n",
    "### $$\\boldsymbol{y} \\sim \\mathcal{N} (\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$$\n",
    "\n",
    "where \n",
    "\n",
    "### $$\\boldsymbol{y} = (y_1,y_2,\\ldots,y_N)^T$$\n",
    "\n",
    "### $$\\boldsymbol{\\mu} = (\\mu_1,\\mu_2,\\ldots,\\mu_N)^T$$ \n",
    "\n",
    "\n",
    "is the *mean vector*, and $\\boldsymbol{\\Sigma}$ is an $N \\times N$ positive semi-definite *covariance matrix*, with elements \n",
    "\n",
    "### $$\\Sigma_{ij}={\\rm cov}(y_i,y_j)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### And then the likelihood generalizes from 1D:\n",
    "\n",
    "\\begin{align}\n",
    "p(y_1 | \\mu, \\sigma) = \\frac{1}{\\sqrt{2 \\pi} \\sigma} \\exp \\left[ - \\frac{(y_1-\\mu)^2}{2 \\sigma^2} \\right] \n",
    "\\end{align}\n",
    "\n",
    "### to ND:\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "p(\\boldsymbol{y} | \\boldsymbol{\\mu}, \\boldsymbol{\\Sigma}) = \\frac{1}{\\sqrt{2 \\pi^N |\\Sigma|} } \\exp \\left[ -\\frac{1}{2} (\\boldsymbol{y} - \\boldsymbol{\\mu})^T \\Sigma^{-1} (\\boldsymbol{y} - \\boldsymbol{\\mu}) \\right] \n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This works because:\n",
    "\n",
    "<img src=\"figures/gaussians_all_the_way_down.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A Gaussian process is an extension of this concept to infinite $N$.\n",
    "\n",
    "This gives rise to a probability distribution over functions, rather than finite $N$ samples. \n",
    "\n",
    "<img src=\"figures/gp.png\" width=500>\n",
    "\n",
    "Informally - infinitely long vector ~ function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Again, for finite number of $y$ drawn from a multivariate normal distribution:\n",
    "\n",
    "### $$\\boldsymbol{y} \\sim \\mathcal{N} (\\boldsymbol{\\mu},\\boldsymbol{\\Sigma})$$\n",
    "\n",
    "This clearly doesn't make sense for infinite $N$, but the essential feature remains the same:\n",
    "### A Gaussian process is completely specified by its *mean function* and *covariance function*.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Incorporating observational error is similar to what you did in the past as well:\n",
    "\n",
    "### $$ y \\sim f(t) + \\epsilon$$ \n",
    "\n",
    "### with deviations from the truth related to the observational uncertainties\n",
    "\n",
    "### $$ \\epsilon \\sim \\mathcal{N}(0, \\sigma_y^2) $$\n",
    "\n",
    "\n",
    "### except now, $f(t)$ is a function not of some parameters, but rather of functions thenselves:\n",
    "\n",
    "###  $$ f(t) \\sim \\mathcal{GP}(m(t), k(t,t'))$$\n",
    "\n",
    "### where I'm switching from $\\mu$ to $m(t)$ and $\\Sigma$ to $k(t, t')$ just to make explicit that these are not vectors.\n",
    "\n",
    "I'm using $k$ because this function that describes the covariance between time $t$ and $t'$ is called a **kernel** function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/random_process.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/weight_space.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"figures/two_views.jpg\" width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## So how do you choose the kernel $k$?\n",
    "\n",
    "Common choices: http://www.cs.toronto.edu/~duvenaud/cookbook/index.html\n",
    "\n",
    "Lets fiddle:\n",
    "\n",
    "## In-class exercise:\n",
    "\n",
    "[Click this](https://distill.pub/2019/visual-exploration-gaussian-processes/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The likelihood\n",
    "\n",
    "The *likelihood* of the data under the GP model is simply:\n",
    "\n",
    "### $$\\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{t}) = \\mathcal{N}(\\boldsymbol{y} \\, | \\, \\boldsymbol{0},K + \\sigma^2 \\mathbb{I}).$$\n",
    "\n",
    "This is a measure of how well the model explains, or predicts, the training set.\n",
    "\n",
    "i.e. **The observed $\\boldsymbol{y}$ are noisy realisations of a latent (unobserved) Gaussian process $\\boldsymbol{f}$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We are marginalizing over the function values $\\boldsymbol{f}$:\n",
    "### $$\\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{t}) = \\int \\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{f},\\boldsymbol{t}) \\, \\mathrm{p}(\\boldsymbol{f} \\,|\\, \\boldsymbol{t}) \\, \\mathrm{d}\\boldsymbol{f},$$\n",
    "\n",
    "where \n",
    "\n",
    "\n",
    "### $$\\mathrm{p}(\\boldsymbol{f} \\,|\\, \\boldsymbol{t}) = \\mathcal{N}(\\boldsymbol{f} \\, | \\, \\boldsymbol{0},K)$$\n",
    "\n",
    "\n",
    "is the *prior*, and \n",
    "\n",
    "\n",
    "### $$\\mathrm{p}(\\boldsymbol{y} \\,|\\, \\boldsymbol{f},\\boldsymbol{t}) = \\mathcal{N}(\\boldsymbol{y} \\, | \\, \\boldsymbol{0},\\sigma^2 \\mathbb{I})$$\n",
    "is the *likelihood*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## You \"condition\" the hyperparameters on some observed data\n",
    "\n",
    "i.e. evaluate the conditional (or predictive) distribution for a given covariance matrix (i.e. covariance function and hyper-parameters), and training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## *Training* the GP...\n",
    "\n",
    "...means maximising the *likelihood* of the model with respect to the hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The kernel trick\n",
    "\n",
    "Consider a linear basis model with arbitrarily many *basis functions*, or *features*, $\\Phi(x)$, and a (Gaussian) prior $\\Sigma_{\\mathrm{p}}$ over the basis function weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You end up with exactly the same expressions for the predictive distribution and the likelihood so long as:\n",
    "### $$k(\\boldsymbol{x},\\boldsymbol{x'}) = \\Phi(\\boldsymbol{x})^{\\mathrm{T}} \\Sigma_{\\mathrm{p}} \\Phi(\\boldsymbol{x'}),$$\n",
    "\n",
    "\n",
    "or, writing $\\Psi(\\boldsymbol{x}) = \\Sigma_{\\mathrm{p}}^{1/2} \\Phi(\\boldsymbol{x})$,\n",
    "\n",
    "\n",
    "### $$k(\\boldsymbol{x},\\boldsymbol{x'}) = \\Psi(\\boldsymbol{x}) \\cdot \\Psi(\\boldsymbol{x'}),$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Thus the covariance function $k$ enables us to go from a (finite) *input space* to a (potentially infinite) *feature space*. This is known as the *kernel trick* and the covariance function is often referred to as the *kernel*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Probabilistic Graphical Model for a GP\n",
    "\n",
    "\n",
    "### Recall:\n",
    "\n",
    "A **probabilistic graphical model** (PGM) is a very useful way of visualizing a generative model.\n",
    "* They sketch out the procedure for how one would generate mock data in practice.\n",
    "* They illustrate the interdependence of model parameters, and the dependence of data on parameters.\n",
    "* _They also (therefore) represent a conditional factorization of the PDF for all the data and model parameters._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Ingredients of a PGM:\n",
    "* **Nodes** represent PDFs for parameters\n",
    "* **Edges** represent conditional relationships\n",
    "* **Plates** represent repeated model components whose contents are **conditionally independent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Types of nodes:\n",
    "* **Circles** represent a PDF. This parameter is a *stochastic* function of the parameters feeding into it.\n",
    "* **Points** represent a delta-function PDF. This parameter is a *deterministic* function of the parameters feeding into it.\n",
    "* **Double circles** (or shading) indicate measured data. They are stochastic in the context of generating mock data, but fixed in the context of parameter inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## If we were dealing with i.i.d. data\n",
    "\n",
    "### $$ y \\sim f(t) + \\epsilon$$ \n",
    "\n",
    "### with deviations from the truth related to the observational uncertainties\n",
    "\n",
    "### $$ \\epsilon \\sim \\mathcal{N}(0, \\sigma_y^2) $$\n",
    "\n",
    "\n",
    "<img src=\"figures/pgm_conditionally_independent.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## With time-series the data are not conditionally independent\n",
    "\n",
    "i.e. you don't have a nice plate:\n",
    "\n",
    "<img src=\"figures/gp_pgm.png\" width=400>\n",
    "\n",
    "From [Rasmussen & Williams (aka the GP bible)](http://www.gaussianprocess.org/gpml/chapters/RW.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Some astronomical applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Spitzer exoplanet transits and eclipses (Evans et al. 2015)\n",
    "\n",
    "<img src=\"figures/Evans_Spitzer.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### GPs to deal with correlated noise in fitting spectra (Narayan et al., 2019)\n",
    "\n",
    "<img src=\"figures/GP_spectra.jpg\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: Mauna Kea CO$_2$ dataset\n",
    "\n",
    "(From Rasmussen & Williams textbook)\n",
    "\n",
    "<img width=\"400\" src=\"figures/RW_mauna_kea.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### GPz photometric redshifts (Almosallam, Jarvis & Roberts 2016)\n",
    "\n",
    "<img src=\"figures/Almosallam_GPz.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How do I choose the kernel/covariance function for a Gaussian process? \n",
    "\n",
    "Taken from: http://www.cs.toronto.edu/~duvenaud/cookbook/index.html\n",
    "\n",
    "The choice of kernel/covariance function determines almost all the generalization properties of a GP model. You are the expert on your modeling problem - so you're the person best qualified to choose the kernel! If you don't yet know enough about kernels to choose a sensible one, read on.\n",
    "\n",
    "### Radial Basis Function kernel (known also as the Gaussian kernel). It has the form:\n",
    "$k_{SE}(x,x′) = \\sigma^{2} \\exp(−\\frac{(x−x′)^2}{2l})$\n",
    "\n",
    "<img src=\"figures/se_kernel.png\" width=\"200\"> <img src=\"figures/se_kernel_draws_s1.png\" width=\"200\">\n",
    "\n",
    "Also called the \"Exponentiated Quadratic\". The SE kernel has become the de-facto default kernel for GPs and SVMs. This is probably because it has some nice properties. It is universal, and you can integrate it against most functions that you need to. Every function in its prior has infinitely many derivatives. \n",
    "\n",
    "It also has only two parameters: \n",
    "\n",
    "* the lengthscale l determines the length of the 'wiggles' in your function. In general, you won't be able to extrapolate more than l units away from your data.\n",
    "* the output variance $\\sigma^2$ determines the average distance of your function away from its mean. Every kernel has this parameter out in front; it's just a scale factor.\n",
    "\n",
    "###  Rational Quadratic Kernel\n",
    "$k_{RQ}(x,x′) = \\sigma^{2} (1 + \\frac{(x−x′)^2}{2 \\alpha l^2})^{-\\alpha}$\n",
    "\n",
    "<img src=\"figures/rq_kernel.png\" width=\"200\"> <img src=\"figures/rq_kernel_draws.png\" width=\"200\">\n",
    "\n",
    "This kernel is equivalent to adding together many SE kernels with different lengthscales. So, GP priors with this kernel expect to see functions which vary smoothly across many lengthscales. The parameter $\\alpha$ determines the relative weighting of large-scale and small-scale variations. When $\\alpha$ goes to $\\infty$, the RQ is identical to the SE.\n",
    "\n",
    "#### Pitfalls of the SE and RQ kernels\n",
    "Most people who set up a GP regression or classification model end up using the Squared-Exp or Rational Quadratic kernels. They are a quick-and-dirty solution that will probably work pretty well for interpolating smooth functions when N is a multiple of D, and when there are no 'kinks' in your function. If your function happens to have a discontinuity or is discontinuous in its first few derivatives (for example, the abs() function), then either your lengthscale will end up being extremely short, and your posterior mean will become zero almost everywhere, or your posterior mean will have 'ringing' effects. Even if there are no hard discontinuities, the lengthscale will usually end up being determined by the smallest 'wiggle' in your function - so you might end up failing to extrapolate in smooth regions if there is even a small non-smooth region in your data.\n",
    "\n",
    "If your data is more than two-dimensional, it may be hard to detect this problem. One indication is if the lengthscale chosen by maximum marginal likelihood never stops becoming smaller as you add more data. This is a classic sign of model misspecification.\n",
    "\n",
    "### Periodic Kernel\n",
    "$k_Per(x,x′) = \\sigma^{2} \\exp(\\frac{-2 \\sin^2 (\\pi |x−x′| /p)}{l^2})$\n",
    "\n",
    "<img src=\"figures/per_kernel.png\" width=\"200\"> <img src=\"figures/per_kernel_draws_s2.png\" width=\"200\">\n",
    "\n",
    "The periodic kernel (derived by David Mackay) allows one to model functions which repeat themselves exactly. Its parameters are easily interpretable:\n",
    "\n",
    "* The period p simply determines the distnace between repititions of the function.\n",
    "* The lengthscale l determines the lengthscale function in the same way as in the SE kernel.\n",
    "\n",
    "\n",
    "###  Locally Periodic Kernel\n",
    "\n",
    "A SE kernel times a periodic results in functions which are periodic, but which can slowly vary over time.\n",
    "\n",
    "$k_LocalPer(x,x′) = \\sigma^{2} \\exp(\\frac{-2 \\sin^2 (\\pi |x−x′| /p)}{l^2}) \\exp(−\\frac{(x−x′)^2}{2l})$\n",
    "\n",
    "<img src=\"figures/longse_times_per.png\" width=\"200\"> <img src=\"figures/longse_times_per_draws_s1.png\" width=\"200\">\n",
    "\n",
    "Most periodic functions don't repeat themselves exactly. To add some flexibility to our model, we can consider adding or multiplying a local kernel such as the squared-exp with our periodic kernel. This will allow us to model functions that are only locally periodic - the shape of the repeating part of the function can now change over time.\n",
    "\n",
    "### Linear Kernel\n",
    "\n",
    "$kLin(x,x′)= \\sigma_b^2 + \\sigma_v^2(x-c)(x′-c)$\n",
    "\n",
    "<img src=\"figures/lin_kernel.png\" width=\"200\"> <img src=\"figures/lin_kernel_draws_s2.png\" width=\"200\">\n",
    "\n",
    "If you use just a linear kernel in a GP, you're simply doing Bayesian linear regression, and good news! You can do this in time O(N) instead of O(N3), so you should probably go use software specifically designed for that.\n",
    "\n",
    "We include the linear kernel here because further on, we'll show you how to combine it with other kernels in order to get some nice properties.\n",
    "\n",
    "The linear kernel is not like the others in that it's non-stationary. A stationary covariance function is one that only depends on the relative position of its two inputs, and not on their absolute location. That means that the parameters of the linear kernel are about specifying the origin:\n",
    "\n",
    "* The offset c determines the x-coordinate of the point that all the lines in the posterior go though. At this point, the function will have zero variance (unless you add noise)\n",
    "* The constant variance $\\sigma_b^2$ determines how far from 0 the height of the function will be at zero. It's a little confusing, becuase it's not specifying that value directly, but rather putting a prior on it. It's equivalent to adding an uncertain offset to our model. See What about the mean function?\n",
    "\n",
    "### Combining Kernels\n",
    "\n",
    "The kernels above are useful if your data is all the same type, but what if you have more than one type of feature, but you still want to regress on all of them together? The standard way to build a kernel over different datatypes is to multiply kernels together.\n",
    "\n",
    "### Multiplying Kernels\n",
    "Multiplying together kernels is the standard way to combine two kernels, especially if they are defined on different inputs to your function.\n",
    "Roughly speaking, multiplying two kernels can be thought of as an AND operation. That is, if you multiply together two kernels, then the resulting kernel will have high value only if both of the two base kernels have a high value. Here are a few examples, in addition to the squared-exp times periodic above:\n",
    "\n",
    "\n",
    "#### Linear times Periodic\n",
    "A linear kernel times a periodic results in functions which are periodic with increasing amplitude as we move away from the origin.\n",
    "\n",
    "<img width=\"200\" src=\"figures/lin_times_per.png\"> <img width=\"200\" src=\"figures/lin_times_per_draws_s2.png\">\n",
    "\n",
    "#### Linear times Linear\n",
    "A linear kernel times another linear kernel results in functions which are quadratic! This trick can be taken to produce Bayesian polynomial regression of any degree.\n",
    "\n",
    "<img width=\"200\" src=\"figures/lin_times_lin.png\"> <img width=\"200\" src=\"figures/lin_times_lin_draws_s7.png\">\n",
    "\n",
    "### Multidimensional Products\n",
    "Multiplying two kernels which each depend only on a single input dimension results in a prior over functions that vary across both dimesions. That is, the function value f(x,y) is only expected to be similar to some other function value f(x′,y′) if x is close to x′ AND y is close to y′.\n",
    "\n",
    "These kernels have the form: $kproduct(x,y,x′,y′)=kx(x,x′)ky(y,y′)$\n",
    "\n",
    "<img width=\"600\" src=\"figures/Sqaured-exp kernel in 2d.png\">\n",
    "\n",
    "Here we show both a multimensional product kernel, and a draw from the corresponding GP prior:\n",
    "\n",
    "\n",
    "### Adding kernels\n",
    "Roughly speaking, adding two kernels can be thought of as an OR operation. That is, if you add together two kernels, then the resulting kernel will have high value if either of the two base kernels have a high value.\n",
    "\n",
    "#### Linear plus Periodic\n",
    "\n",
    "<img width=\"200\" src=\"figures/lin_plus_per.png\"> <img width=\"200\" src=\"figures/lin_plus_per_draws_s2.png\">\n",
    "\n",
    "A linear kernel plus a periodic results in functions which are periodic with increasing mean as we move away from the origin.\n",
    "\n",
    "### Automatically Choosing a Kernel\n",
    "After reading all this advice, you might decide that you're not sure which kernel is approriate for your problem. In fact, you might decide that choosing the kernel is one of the main difficulties in doing inference - and just as you don't know what the true parameters are, you also don't know what the true kernel is. Probably, you should try out a few different kernels at least, and compare their marginal likelihood on your training data.\n",
    "\n",
    "However, it might be annoying to write down all the different kernels you want to try, especially if there are more than a few variations you're interested in. If want to let the computer run a search over kernels for you, we've made code available to do just that. We wrote about these automatic searches in a paper.\n",
    "\n",
    "### Further Reading\n",
    "There is a massive literature about kernels for Gaussian process and SVMs. Probably the most comprehensive collection of information about covariance functions for Gaussian processes is chapter 4 of the book Gaussian Processes for Machine Learning. Another practical guide with lots of examples (and example code!) is in the documentation for the python GPy library. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In-class exercise: Gaussian Process on Cepheids\n",
    "Let's generate a simple Cepheids-like dataset: observations of $y$ with reported uncertainties $\\sigma_y$, at given $x$ values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "\n",
    "import numpy as np\n",
    "import pylab as plt\n",
    "\n",
    "xlimits = [0,350]\n",
    "ylimits = [0,250]\n",
    "\n",
    "def generate_data(seed=None):\n",
    "    \"\"\"\n",
    "    Generate a 30-point data set, with x and sigma_y as standard, but with\n",
    "    y values given by\n",
    "\n",
    "    y = a_0 + a_1 * x + a_2 * x**2 + a_3 * x**3 + noise\n",
    "    \"\"\"\n",
    "    Ndata = 30\n",
    "\n",
    "    xbar = 0.5*(xlimits[0] + xlimits[1])\n",
    "    xstd = 0.25*(xlimits[1] - xlimits[0])\n",
    "\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed=seed)\n",
    "\n",
    "    x = xbar + xstd * np.random.randn(Ndata)\n",
    "\n",
    "    meanerr = 0.025*(xlimits[1] - xlimits[0])\n",
    "\n",
    "    sigmay = meanerr + 0.3 * meanerr * np.abs(np.random.randn(Ndata))\n",
    "\n",
    "    a = np.array([37.2,0.93,-0.002,0.0])\n",
    "    y = a[0] + a[1] * x + a[2] * x**2 + a[3] * x**3 + sigmay*np.random.randn(len(x))\n",
    "\n",
    "    return x,y,sigmay\n",
    "\n",
    "def plot_yerr(x, y, sigmay):\n",
    "    \"\"\"\n",
    "    Plot an (x,y,sigma) dataset as a set of points with error bars \n",
    "    \"\"\"\n",
    "    plt.errorbar(x, y, yerr=sigmay, fmt='.', ms=7, lw=1, color='k')\n",
    "    plt.xlabel('$x$', fontsize=16)\n",
    "    plt.ylabel('$y$', fontsize=16)\n",
    "    plt.xlim(*xlimits)\n",
    "    plt.ylim(*ylimits)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "(x, y, sigmay) = generate_data(seed=13)\n",
    "\n",
    "plot_yerr(x, y, sigmay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fitting the Gaussian Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF as SquaredExponential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Defining the kernel/covariance Function\n",
    "\n",
    "As you know by now, we need to define a kernel/covariance function, for populating the covariance matrix of our GP. \n",
    "\n",
    "We will use a Gaussian kernel/covariance (also referred to as a \"squared exponential\" or a \"radial basis function\" RBF). The squared exponential kernel has one hyper-parameter, the length scale that is the Gaussian width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "h = 10.0\n",
    "\n",
    "kernel = SquaredExponential(length_scale=h, length_scale_bounds=(0.01, 1000.0))\n",
    "gp0 = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, let's draw some samples from the unconstrained process, o equivalently, the prior. Each sample is a function $y(x)$, which we evaluate on a grid. We'll need to assert a value for the kernel hyperparameter $h$, which dictates the correlation length between the datapoints. That will allow us to compute a mean function (which for simplicity we'll set to the mean observed $y$ value), and a covariance matrix that captures the correlations between datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "xgrid = np.atleast_2d(np.linspace(0, 399, 100)).T\n",
    "print(\"y(x) will be predicted on a grid of length\", len(xgrid))\n",
    "\n",
    "# Draw three sample y(x) functions:\n",
    "draws = gp0.sample_y(...\n",
    "\n",
    "print(\"Drew 3 samples, stored in an array with shape \", draws.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's plot these, to see what our prior looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start a 4-panel figure:\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "# Plot our three prior draws:\n",
    "ax = fig.add_subplot(221)\n",
    "ax.plot(xgrid, draws[:,0], '-r')\n",
    "ax.plot(xgrid, draws[:,1], '-g')\n",
    "ax.plot(xgrid, draws[:,2], '-b', label='Rescaled prior sample $y(x)$')\n",
    "ax.set_xlim(0, 399)\n",
    "ax.set_ylim(-5, 5)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y(x)$')\n",
    "ax.legend(fontsize=8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Each predicted $y(x)$ is drawn from a Gaussian of unit variance, and with off-diagonal elements determined by the covariance function. \n",
    "\n",
    "Try changing `h` to see what happens to the smoothness of the predictions. \n",
    "\n",
    "> Go back up to the cell where `h` is assigned, and re-run that cell and the subsequent ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For our data to be well interpolated by this Gaussian Process, it will need to be rescaled such that it has zero mean and unit variance. There are [standard methods for doing this](http://scikit-learn.org/stable/modules/preprocessing.html), but we'll do this rescaling here for transparency - and so we know what to add back in later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Rescale():\n",
    "    def __init__(self, y, err):\n",
    "        self.original_data = y\n",
    "        self.original_err = err\n",
    "        self.mean = np.mean(y)\n",
    "        self.std = np.std(y)\n",
    "        self.transform()\n",
    "        return\n",
    "    def transform(self):\n",
    "        self.y = (self.original_data - self.mean) / self.std\n",
    "        self.err = self.original_err / self.std\n",
    "        return()\n",
    "    def invert(self, scaled_y, scaled_err):\n",
    "        return (scaled_y * self.std + self.mean, scaled_err * self.std)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "rescaled = Rescale(y, sigmay)\n",
    "print('Mean, variance of original data: ',np.round(np.mean(y)), np.round(np.var(y)))\n",
    "print('Mean, variance of rescaled data: ',np.round(np.mean(rescaled.y)), np.round(np.var(rescaled.y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "y2, sigmay2 = rescaled.invert(rescaled.y, rescaled.err)\n",
    "print('Mean, variance of inverted, rescaled data: ',np.round(np.mean(y2)), np.round(np.var(y2)))\n",
    "print('Maximum differences in y, sigmay, after round trip: ',np.max(np.abs(y2 - y)), np.max(np.abs(sigmay2 - sigmay)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Constraining the GP\n",
    "\n",
    "Now, using the same covariance function, lets \"fit\" the GP by constraining each draw from the GP to go through our data points, and _optimizing_ the length scale hyperparameter `h`. \n",
    "\n",
    "Let's first look at how this would work for two data points with no uncertainty. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Choose two of our (rescaled) datapoints:\n",
    "x1 = np.array([x[10], x[12]])\n",
    "rescaled_y1 = np.array([rescaled.y[10], rescaled.y[12]])\n",
    "rescaled_sigmay1 = np.array([rescaled.err[10], rescaled.err[12]])\n",
    "\n",
    "# Instantiate a GP model, with initial length_scale h=10:\n",
    "kernel = SquaredExponential(...\n",
    "gp1 = GaussianProcessRegressor(...\n",
    "\n",
    "# Fit it to our two noiseless datapoints:\n",
    "gp1.fit(...\n",
    "\n",
    "# We have fit for the length scale parameter: print the result here:\n",
    "params = gp1.kernel_.get_params()\n",
    "print('Best-fit kernel length scale =', params['length_scale'],'cf. input',10.0)\n",
    "\n",
    "# Now predict y(x) everywhere on our xgrid: \n",
    "rescaled_ygrid1, rescaled_ygrid1_err = gp1.predict(...\n",
    "\n",
    "# And undo scaling, of both y(x) on our grid, and our two constraining data points:\n",
    "ygrid1, ygrid1_err = rescaled.invert(...\n",
    "y1, sigmay1 = rescaled.invert(..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = fig.add_subplot(222)\n",
    "ax.plot(xgrid, ygrid1, '-', color='gray', label='Posterior mean $y(x)$')\n",
    "ax.fill(np.concatenate([xgrid, xgrid[::-1]]),\n",
    "        np.concatenate([(ygrid1 - ygrid1_err), (ygrid1 + ygrid1_err)[::-1]]),\n",
    "        alpha=0.3, fc='gray', ec='None', label='68% confidence interval')\n",
    "ax.plot(x1, y1, '.k', ms=6, label='Noiseless constraints')\n",
    "ax.set_xlim(0, 399)\n",
    "ax.set_ylim(0, 399)\n",
    "ax.set_xlabel('$x$')\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the absence of information, the GP tends to produce $y(x)$ that fluctuate around the prior mean function, which we chose to be a constant. Let's draw some samples from the posterior PDF, and overlay them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "draws = gp1.sample_y(xgrid, n_samples=3)\n",
    "for k in range(3):\n",
    "    draws[:,k], dummy = rescaled.invert(draws[:,k], np.zeros(len(xgrid)))\n",
    "\n",
    "ax.plot(xgrid, draws[:,0], '-r')\n",
    "ax.plot(xgrid, draws[:,1], '-g')\n",
    "ax.plot(xgrid, draws[:,2], '-b', label='Posterior sample $y(x)$')\n",
    "ax.legend(fontsize=8)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "See how the posterior sample $y(x)$ functions all pass through the constrained points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Choose two of our datapoints:\n",
    "x2 = np.array([x[10], x[12]])\n",
    "rescaled_y2 = np.array([rescaled.y[10], rescaled.y[12]])\n",
    "rescaled_sigmay2 = np.array([rescaled.err[10], rescaled.err[12]])\n",
    "\n",
    "# Instantiate a GP model, including observational errors:\n",
    "kernel = SquaredExponential(...\n",
    "gp2 = GaussianProcessRegressor(...\n",
    "\n",
    "# Fit it to our two noisy datapoints:\n",
    "gp2.fit(...\n",
    "\n",
    "# We have fit for the length scale parameter: print the result here:\n",
    "params = gp2.kernel_.get_params()\n",
    "print('Best-fit kernel length scale =', params['length_scale'],'cf. input',10.0)\n",
    "\n",
    "# Now predict y(x) everywhere on our xgrid: \n",
    "rescaled_ygrid2, rescaled_ygrid2_err = gp2.predict(...\n",
    "\n",
    "# And undo scaling:\n",
    "ygrid2, ygrid2_err = rescaled.invert(...\n",
    "y2, sigmay2 = rescaled.invert(...\n",
    "\n",
    "# Draw three posterior sample y(x):\n",
    "draws = gp2.sample_y(xgrid, n_samples=3)\n",
    "for k in range(3):\n",
    "    draws[:,k], dummy = rescaled.invert(draws[:,k], np.zeros(len(xgrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = fig.add_subplot(223)\n",
    "\n",
    "def gp_plot(ax, xx, yy, ee, datax, datay, datae, samples, legend=True):\n",
    "    ax.cla()\n",
    "    ax.plot(xx, yy, '-', color='gray', label='Posterior mean $y(x)$')\n",
    "    ax.fill(np.concatenate([xx, xx[::-1]]),\n",
    "            np.concatenate([(yy - ee), (yy + ee)[::-1]]),\n",
    "            alpha=0.3, fc='gray', ec='None', label='68% confidence interval')\n",
    "    ax.errorbar(datax, datay, datae, fmt='.k', ms=6, label='Noisy constraints')\n",
    "    ax.set_xlim(0, 399)\n",
    "    ax.set_ylim(0, 399)\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$y(x)$')\n",
    "    ax.plot(xgrid, samples[:,0], '-r')\n",
    "    ax.plot(xgrid, samples[:,1], '-g')\n",
    "    ax.plot(xgrid, samples[:,2], '-b', label='Posterior sample $y(x)$')\n",
    "    if legend: ax.legend(fontsize=8)\n",
    "    return\n",
    "\n",
    "gp_plot(ax, xgrid, ygrid2, ygrid2_err, x2, y2, sigmay2, draws, legend=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now, the posterior sample $y(x)$ functions pass through the constraints _within the errors_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Using all the Data\n",
    "\n",
    "Now let's extend the above example to use all of our datapoints. This additional information should pull the predictions further away from the initial mean function. We'll also compute the marginal log likelihood of the best fit hyperparameter, in case we want to compare this choice of kernel with another one (in the exercises, for example)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Use all of our datapoints:\n",
    "x3 = x\n",
    "rescaled_y3 = rescaled.y\n",
    "rescaled_sigmay3 = rescaled.err\n",
    "\n",
    "# Instantiate a GP model, including observational errors:\n",
    "kernel = SquaredExponential(...\n",
    "# Could comment this out, and then import and use an \n",
    "# alternative kernel here. \n",
    "\n",
    "gp3 = GaussianProcessRegressor(...\n",
    "\n",
    "# Fit it to our noisy datapoints:\n",
    "gp3.fit(...\n",
    "\n",
    "# Now predict y(x) everywhere on our xgrid: \n",
    "rescaled_ygrid3, rescaled_ygrid3_err = gp3.predict(...\n",
    "\n",
    "# And undo scaling:\n",
    "ygrid3, ygrid3_err = rescaled.invert(...\n",
    "y3, sigmay3 = rescaled.invert(...\n",
    "\n",
    "# We have fitted the length scale parameter - print the result here:\n",
    "params = gp3.kernel_.get_params()\n",
    "print('Kernel: {}'.format(gp3.kernel_))\n",
    "print('Best-fit kernel length scale =', params['length_scale'],'cf. input',10.0)\n",
    "print('Marginal log-Likelihood: {:.3f}'.format(gp3.log_marginal_likelihood(gp3.kernel_.theta)))\n",
    "\n",
    "# Draw three posterior sample y(x):\n",
    "draws = gp3.sample_y(xgrid, n_samples=3)\n",
    "for k in range(3): \n",
    "    draws[:,k], dummy = rescaled.invert(draws[:,k], np.zeros(len(xgrid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ax = fig.add_subplot(224)\n",
    "\n",
    "gp_plot(ax, xgrid, ygrid3, ygrid3_err, x3, y3, sigmay3, draws, legend=True)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now see the Gaussian Process model providing a smooth interpolation between the points. The posterior samples show fluctuations, but all are plausible under our assumptions."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
